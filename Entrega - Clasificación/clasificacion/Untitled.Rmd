---
title: "Untitled"
output: html_document
---

https://www.analyticsvidhya.com/blog/2015/08/learning-concept-knn-algorithms-programming/

```{r cars}
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
str(wbcd)
wbcd
```

Drop the id feature
```{r cars}
wbcd <- wbcd[,-1]
wbcd
```

Table of diagnosis
```{r cars}
# Table of diagnosis
table(wbcd$diagnosis)
```

```{r cars}
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant"))
table(wbcd$diagnosis)
```

```{r cars}
# Table or proportions with more informative labels
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
```
```{r cars}
# Summarize three numeric features
summary(wbcd[,c("radius_mean", "area_mean", "smoothness_mean")])
# Normalize the wbcd data
#The first variable in our data set (after removal of id) is ‘diagnosis_result’ which is not numeric in nature. So, we start from 2nd variable. The function lapply() applies normalize() to each feature in the data frame. The final result is stored to prc_n data frame using as.data.frame() function
wbcd_n <- as.data.frame(lapply(wbcd[,2:31], scale, center = TRUE, scale = TRUE))
# Confirm that normalization worked
summary(wbcd_n[,c("radius_mean", "area_mean", "smoothness_mean")])
boxplot(wbcd_n[,c("radius_mean", "area_mean", "smoothness_mean")])
```
```{r}
plot(wbcd[,2:5])
plot(wbcd_n[,1:4], col=wbcd[,1])
cor(wbcd[,2:5])
cor(wbcd_n[,1:4])
```
```{r}
# Create training and test data
shuffle_ds <- sample(dim(wbcd_n)[1])
eightypct <- (dim(wbcd_n)[1] * 80) %/% 100
wbcd_train <- wbcd_n[shuffle_ds[1:eightypct], ]
wbcd_test <- wbcd_n[shuffle_ds[(eightypct+1):dim(wbcd_n)[1]], ]

# Create labels for training and test data
wbcd_train_labels <- wbcd[shuffle_ds[1:eightypct], 1]
wbcd_test_labels <- wbcd[shuffle_ds[(eightypct+1):dim(wbcd_n)[1]], 1]
```

The knn () function needs to be used to train a model for which we need to install a package ‘class’. The knn() function identifies the k-nearest neighbors using Euclidean distance where k is a user-specified number.

```{r}
library(class)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=21)
wbcd_test_pred
```

```{r}
library(gmodels)
CrossTable( x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
```

The test data consisted of 114 observations. Out of which 76 cases have been accurately predicted (TN->True Negatives) as Benign (B) in nature which constitutes 39.5%.

Also, 43 out of 114 observations were accurately predicted (TP-> True Positives) as Malignant (M) in nature which constitutes 37.7%. Thus a total of 43 out of 145 predictions where TP i.e, True Positive in nature.

There were 31 cases of False Negatives (FN) meaning 31 cases were recorded which actually are malignant in nature but got predicted as benign. 

There were 26 cases of False Positives (FP) meaning 26 cases were actually benign in nature but got predicted as malignant.

The total accuracy of the model is 60 %( (TN+TP)/35) which shows that there may be chances to improve the model performance

```{r}
# Evaluating model performance
table(wbcd_test_pred,wbcd_test_labels)
```

```{r}
require(caret)
knnModel <- train(x = wbcd_train, y = wbcd_train_labels, method = "knn")
knnModel
```
```{r}
knnModel <- train(wbcd_train, wbcd_train_labels, method="knn", metric="Accuracy", tuneGrid = data.frame(.k=1:15))
knnModel
plot(knnModel)
```
```{r}
knnModel <- train(x = wbcd[shuffle_ds[1:eightypct],-1], y = wbcd[shuffle_ds[1:eightypct],1], method = "knn", preProc = c("center", "scale"))
knnModel
plot(knnModel)
```

```{r}
knnPred <- predict(knnModel, newdata = wbcd[shuffle_ds[(eightypct+1):dim(wbcd_n)[1]], -1])
knnPred
```
```{r}
postResample(pred = knnPred, obs = wbcd[shuffle_ds[(eightypct+1):dim(wbcd_n)[1]], 1])
```


Try with different k choices and do a quick comparison. You can draw a plot to show the results.
```{r}
ctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(12345)
knnModel <- train(wbcd_train, wbcd_train_labels, method="knn", trControl=ctrl, metric="Accuracy", tuneLength=20, preProc= c("center", "scale"))
knnModel
plot(knnModel)
```

